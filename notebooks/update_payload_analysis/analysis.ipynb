{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11bf59ca-8e4e-4ee1-9008-8a9e340712fe",
   "metadata": {},
   "source": [
    "# Update Payload Analysis\n",
    "\n",
    "\n",
    "The update payload is the data that describes an integrity assured, authorized update to a specific DID document. The payload is NOT published on chain, only a hash of the payload is published by one or more beacons. During resolution, a resolver MUST retrieve the update payload that matches the hash for the beacon signal they are processing. They either retrieve this from a CAS (e.g. IPFS) or in a sidecar manner from the DID controller. In either instances, the DID controller SHOULD keep a record of all DID updates across time for the DIDs that they care about.\n",
    "\n",
    "At a minimum it MUST contain:\n",
    "\n",
    "1. A representation of the update \n",
    "2. A signature over this update\n",
    "\n",
    "The signature will always be a constant size and the update will vary depending on the changes being made to the DID document. \n",
    "\n",
    "**Note: There is a discussion to be had about how we represent an update. In this notebook I will look at JSON patch and JSON0, we could probably also define our own custom thingy for this but we do not advise it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2723164-deba-4986-a089-6027865676f7",
   "metadata": {},
   "source": [
    "# Example Data\n",
    "\n",
    "## JSON0 or JSON Patch\n",
    "\n",
    "Both [JSON0](https://github.com/ottypes/json0) and [JSON Patch](https://jsonpatch.com/) provide a data model to define generalized operations that transform JSON. The below cell shows both formats describing how to mutate a DID document to add a service endpoint. JSON patch is marginally larger (~19 bytes in the below example). We should compare across a few more typical updates for a more complete size analysis.\n",
    "\n",
    "However, regardless of this size analysis I am advocating that that we use JSON patch for a number of reasons:\n",
    "\n",
    "- JSON Patch is an RFC specified at IETF - https://datatracker.ietf.org/doc/html/rfc6902 (JSON0 is defined in a repo and seems primarily adopted within JavaScript stacks)\n",
    "- JSON Patch has multiple implementations: JS, Python and [Rust](https://crates.io/crates/json-patch). I only know of a JS implementation of JSON0.\n",
    "- JSON Patch been used with JSONLD, including a [defined @context file](https://github.com/digitalbazaar/jsonld-patch/blob/master/lib/contexts/json-ld-patch-v1.json) that describes the JSON Patch operations. This is work we would have to do ourselves if we wanted to use JSON0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b670275c-45e4-4267-a42e-ac4129b7786d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON0 Update size : 164\n",
      "JSON Patch Update size: 183\n",
      "Signature size:  138\n",
      "Rough total size (w/ JSON patch) :  321\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import copy\n",
    "import json\n",
    "\n",
    "json_0_update_repr = {'p': ['service', 4],\n",
    " 'li': {'id': '#linked-domain',\n",
    "  'type': 'LinkedDomains',\n",
    "  'serviceEndpoint': 'https://contact-me.com'}}\n",
    "\n",
    "json_patch_update_repr = [{'op': 'add',\n",
    "  'path': '/service/4',\n",
    "  'value': {'id': '#linked-domain',\n",
    "   'type': 'LinkedDomains',\n",
    "   'serviceEndpoint': 'https://contact-me.com'}}]\n",
    "\n",
    "\n",
    "\n",
    "json0_size = sys.getsizeof(json.dumps(json_0_update_repr))\n",
    "\n",
    "json_patch_size = sys.getsizeof(json.dumps(json_patch_update_repr))\n",
    "\n",
    "\n",
    "\n",
    "## This is a Ecdsa Secp2561 signature encoded use base58\n",
    "signature = 'z381yXYmxU8NudZ4HXY56DfMN6zfD8syvWcRXzT9xD9uYoQToo8QsXD7ahM3gXTzuay5WJbqTswt2BKaGWYn2hHhVFKJLXaDz'\n",
    "\n",
    "sig_size = sys.getsizeof(signature)\n",
    "total_size = json_patch_size + sig_size\n",
    "\n",
    "print(f\"JSON0 Update size : {json0_size}\\nJSON Patch Update size: {json_patch_size}\")\n",
    "print(\"Signature size: \", sig_size)\n",
    "print(\"Rough total size (w/ JSON patch) : \", total_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b68bff-2a30-4b37-a380-e1bbffef7527",
   "metadata": {},
   "source": [
    "# 1. A Minimal Update Payload\n",
    "\n",
    "So, the smallest update payload we could define would be JUST these two fields. Infact, if we really care about the bytes we could follow Bitcoin and create some custom encoding format (a la https://en.bitcoin.it/wiki/Transaction). That would be it, maybe some minial flag to indicate the end of the update payload and start of the signature.\n",
    "\n",
    "**Byte requirements: 1-4 additional bytes** \n",
    "\n",
    "Everything else about how to interpret, parse and verify this update payload would be left to the spec. This includes:\n",
    "\n",
    "1. Which keys/verificationMethods are authorized to sign this update?\n",
    "2. Which key/verificationMethod did produce the signature?\n",
    "3. How the data being signed over canonicalized?\n",
    "4. Which hash function should be used to hash the canonicalized data?\n",
    "5. How is the signature serialized?\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- Everything is custom. For people to support this DID method they have to read, understand and implement the spec in its entirety. There is no overlap with existing DID method implementations and data securing mechanisms (e.g. Data Integrity).\n",
    "- No obvious link between the DID controller and the signature. How exactly to define which keys/vms are authorized and how to indicate which key was used to sign the update is not clear. It likely requires additional data to be added to this representation.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "We want to use Data Integrity to secure a JSON representation of the update payload. **I think we are aligned with this.**\n",
    "\n",
    "## Why Data Integrity\n",
    "\n",
    "Data Integrity describes a standardized way to add a proof to a JSON document such that the canonicalization mechanism, hash function and signature scheme can all be interpretted by inspecting at the proof object.\n",
    "\n",
    "Note: I have not put together an example of this minima payload as it is very dependent on the encoding serialization format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b08fa-7f41-4d40-923b-652e51d3ddda",
   "metadata": {},
   "source": [
    "# 2. Securing a Minimal JSON Update Payload\n",
    "\n",
    "If we want to use Data Integrity, we do not necessarily have to use JSON-LD. It is possible to add a Data Integrity proof to a standard JSON object (see [Example 2](https://www.w3.org/TR/vc-data-integrity/#example-a-simple-signed-json-data-document)).\n",
    "\n",
    "So perhaps the next minimal update payload we could define would be a JSON with a single property, say `patch` for the update representation with a proof added.\n",
    "\n",
    "Note that by using a Data Integrity `proof`, the following fields are required:\n",
    "\n",
    "- type\n",
    "- cryptosuite\n",
    "- proofPurpose\n",
    "- proofValue\n",
    "\n",
    "Additionally, including the `verificationMethod` property is optional but it gives a way to specify which public key created the signature. We mayp want to require in our specification that this public key is a public key controlled by the DID being updated.\n",
    "\n",
    "See example below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae96bb-e84d-4bd3-aba0-8ca916720148",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53310a45-4863-42fc-9e35-f1440890d0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patch': [{'op': 'add',\n",
       "   'path': '/service/4',\n",
       "   'value': {'id': '#linked-domain',\n",
       "    'type': 'LinkedDomains',\n",
       "    'serviceEndpoint': 'https://contact-me.com'}}],\n",
       " 'proof': {'type': 'DataIntegrityProof',\n",
       "  'cryptosuite': 'secp-schnorr-2024',\n",
       "  'verificationMethod': 'did:btc:6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis#initialKey',\n",
       "  'proofPurpose': 'assertionMethod',\n",
       "  'proofValue': 'z381yXYmxU8NudZ4HXY56DfMN6zfD8syvWcRXzT9xD9uYoQToo8QsXD7ahM3gXTzuay5WJbqTswt2BKaGWYn2hHhVFKJLXaDz'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_json_update_payload = {\n",
    "    'patch': json_patch_update_repr,\n",
    "    'proof': {\n",
    "        \"type\": \"DataIntegrityProof\",\n",
    "        \"cryptosuite\": \"secp-schnorr-2024\",\n",
    "        \"verificationMethod\": \"did:btc:6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis#initialKey\",\n",
    "        \"proofPurpose\": \"assertionMethod\",\n",
    "        \"proofValue\": \"z381yXYmxU8NudZ4HXY56DfMN6zfD8syvWcRXzT9xD9uYoQToo8QsXD7ahM3gXTzuay5WJbqTswt2BKaGWYn2hHhVFKJLXaDz\"\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "minimal_json_update_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2502c-87b6-4b4f-bce8-855efe53050f",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "I actually don't think this is terrible. It perhaps is the minimal thing that could work. \n",
    "\n",
    "A couple of things to note.\n",
    "\n",
    "- We are not signing JSON-LD here. This means we don't need a `@context` property. It also means the RDF canonicalization will not be possible, our cryptosuite would have to specify [JCS canonicalization](https://www.rfc-editor.org/rfc/rfc8785). We may need to define an additional cryptosuite for signing JSONLD VCs if we want to support RDF canonicalization.\n",
    "- The DID controller would identify the key in their current DID document that they used to create this proof using the `verificationMethod` property. It would be up to the resolver to check that this actually is a key controlled by the DID controller in the latest DID document at that point in the resolution chain. The proof would verify with any valid `verificationMethod`.\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- This is NOT an authorization object. No clear authorization can be understood from the payload itself.\n",
    "- The spec is still defining a lot of custom things out of band. How to interpret the verificationMethod and check that it is authorized to sign off on this update being the main one. But also, what `patch` means in this context.\n",
    "- There is no JSONLD context. The context file provides a human readable description for each of the properties, so it would give a mechanism to define `patch`. However, I actually am not convinced this is an issue. The spec can just say `patch` is a JSON patch and refer to the IETF RFC https://datatracker.ietf.org/doc/html/rfc6902/. \n",
    "- No ability to support delegation. Who is authorized to sign an update would be fixed by the spec, which would have to define how this authorization is bound to the DID controller.\n",
    "- Without a `@context` property, the Data Integrity proof must be recognised and understood in some out of band way. Wheras the `@context` property would point to the specification against which the proof can be understood. Implementors would be able to better evaluate if they support this proof type.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Maybe we should have the `@context` property? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731860ea-0556-48da-a150-40b7f9234038",
   "metadata": {},
   "source": [
    "# 3. Securing a Minimal JSONLD Update Payload\n",
    "\n",
    "If we add the `@context` property, our cryptosuite could now use RDF canonicalization if we want to. If we go down that route, we must also add an additional context that defines our `patch` property and all the nested fields it might have. Fortunately, Digital Bazaar have already done this work for us and the @context for JSON patch can be found here - https://w3id.org/json-ld-patch/v1.\n",
    "\n",
    "Note: this has much the same limitations as 2. in respect to the spec having to define how authorizations are bound to the DID controller. See above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3cb73a-c998-4e73-a81c-5033cc1a3ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@context': ['https://w3id.org/security/data-integrity/v2',\n",
       "  'https://w3id.org/json-ld-patch/v1'],\n",
       " 'patch': [{'op': 'add',\n",
       "   'path': '/service/4',\n",
       "   'value': {'id': '#linked-domain',\n",
       "    'type': 'LinkedDomains',\n",
       "    'serviceEndpoint': 'https://contact-me.com'}}],\n",
       " 'proof': {'type': 'DataIntegrityProof',\n",
       "  'cryptosuite': 'secp-schnorr-2024',\n",
       "  'verificationMethod': 'did:btc:6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis#initialKey',\n",
       "  'proofPurpose': 'assertionMethod',\n",
       "  'proofValue': 'z381yXYmxU8NudZ4HXY56DfMN6zfD8syvWcRXzT9xD9uYoQToo8QsXD7ahM3gXTzuay5WJbqTswt2BKaGWYn2hHhVFKJLXaDz'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_jsonld_update_payload = {\n",
    "    \"@context\": [\"https://w3id.org/security/data-integrity/v2\", \"https://w3id.org/json-ld-patch/v1\"],\n",
    "    \"patch\": json_patch_update_repr,\n",
    "    \"proof\": {\n",
    "        \"type\": \"DataIntegrityProof\",\n",
    "        \"cryptosuite\": \"secp-schnorr-2024\",\n",
    "        \"verificationMethod\": \"did:btc:6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis#initialKey\",\n",
    "        \"proofPurpose\": \"assertionMethod\",\n",
    "        \"proofValue\": signature\n",
    "  }\n",
    "}\n",
    "\n",
    "minimal_jsonld_update_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716bb95a-e083-426a-b873-17f6059070e5",
   "metadata": {},
   "source": [
    "# 4. Using Capabilities\n",
    "\n",
    "All of the above examples have NOT been authorization objects. I.e. the data objects by themselves do not provide any indication of their sematics. What they mean and how they should be interpretted are all dependent on the protocol.\n",
    "\n",
    "Capabilities are a way to define these semantics. They provide a consistent way to define where these capabilities are targetting, such that the updates cannot be taken out of context and misrepresented. This update payload is an invocation of a capability, the capability to update a specific DID document. The previous examples (1,2 and 3) are not authorization objects, they can only be understood within the context of the protocol. However, these data objects can and will be taken out of context. If we wanted to make the previous examples authorization objects we would have to add additional properties to the JSON object that define the target of the capability and a mechanism to identify who is authorized to invoke the capability.\n",
    "\n",
    "**OR**, we could use a standard capabilities data format (ZCaps-LD) that has already thought through these problems AND optionally supports the ability for the delegation and scoping of capabilites. For example, it MAY be possible to delegate the ability for a key to ONLY update serviceEndpoints. Note: supporting this is not trivial, but ZCaps-LD gives us a coherent way to support these features if we want to.\n",
    "\n",
    "## Why ZCaps-LD\n",
    "\n",
    "If we have decided to use JSON as a data format AND we want to secure this data format using Data Integrity proofs then using ZCaps-LD makes sense. It is a JSONLD (which is JSON) data format specification that provides a coherent mechanism to define capabilities that are secured with Data Integrity proofs.\n",
    "\n",
    "## Understanding ZCaps\n",
    "\n",
    "The ZCap spec defines a root capability as a JSON object including the following properties:\n",
    "\n",
    "- `@context` value of \"https://w3id.org/zcap/v1\"\n",
    "- `id` - A root zcap MUST have an id that is a string that expresses a URN. This ID can always be dereferenced by the verifier system if it is a valid root zcap for a particular endpoint.\n",
    "- `invocationTarget` - A root zcap MUST have an invocationTarget that is a string that expresses a URI. The invocation target identifies where the zcap may be invoked, and identifies the target object for which the root zcap expresses authority. `\n",
    "- `controller`\n",
    "\n",
    "Now, for our use case the verifier system the *can always dereference the ID of the root capability* needs to be anyone who is resolving the DID. So our spec currently defines a deterministic algorithm to go from a DID to the root capability for updating that DID - see [Section 3.3.1](https://gl1.dcdpr.com/btcr/btcr/-/blob/main/spec/index.md?ref_type=heads#3311-root-capability) of the spec. The key point is that anyone with a DID, can generate the root capability for updating that DID.\n",
    "\n",
    "**Important: THIS DOES NOT GO IN THE UPDATE PAYLOAD**\n",
    "\n",
    "## What properties do go in the update payload?\n",
    "\n",
    "> When invoking using a DI proof, a capability invocation proof must be attached to a document that is acceptable by the API, as defined by the specific API being accessed. The capability invocation proof MUST include the intended `invocationTarget`, the root zcap ID in the `capability` property, and the action to be taken in the `capabilityAction` property. The same controller rules apply as in the HTTP signature case. [https://w3c-ccg.github.io/zcap-spec/#invoking-root-capability](https://w3c-ccg.github.io/zcap-spec/#invoking-root-capability)\n",
    "\n",
    "The following fields would need to be addedto the Data Integrity proof\n",
    "\n",
    "- `capability` - The id of the root capability e.g. `urn:zcap:root:did%3Abtc%3Az6MkuUCMtGc31Ez1dG19PL8S4XHEfwBxZuWGBcFAjkEVByxr`\n",
    "- `capabilityAction` - E.g.  Write\n",
    "- `invocationTarget` - The DID being updated e.g. `did:btc1::z6MkuUCMtGc31Ez1dG19PL8S4XHEfwBxZuWGBcFAjkEVByxr`\n",
    "\n",
    "Additionally, from the spec `An invocation SHOULD have an id (which may also serve as a nonce). Any other properties are considered arguments to the invocation.` So maybe we want one of those?\n",
    "\n",
    "Lets look at an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14912394-395e-420d-903c-4b4cc639d653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@context': ['https://w3id.org/zcap/v1',\n",
       "  'https://w3id.org/security/data-integrity/v2',\n",
       "  ' '],\n",
       " 'patch': [{'op': 'add',\n",
       "   'path': '/service/4',\n",
       "   'value': {'id': '#linked-domain',\n",
       "    'type': 'LinkedDomains',\n",
       "    'serviceEndpoint': 'https://contact-me.com'}}],\n",
       " 'proof': {'type': 'DataIntegrityProof',\n",
       "  'cryptosuite': 'secp-schnorr-2024',\n",
       "  'verificationMethod': 'did:btc:6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis#initialKey',\n",
       "  'invocationTarget': 'did:btc:6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis',\n",
       "  'capability': 'urn:zcap:root:did%3Abtc%3A6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis',\n",
       "  'capabilityAction': 'Write',\n",
       "  'proofPurpose': 'assertionMethod',\n",
       "  'proofValue': 'z381yXYmxU8NudZ4HXY56DfMN6zfD8syvWcRXzT9xD9uYoQToo8QsXD7ahM3gXTzuay5WJbqTswt2BKaGWYn2hHhVFKJLXaDz'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zcaps_invocation_update_payload = {\n",
    "    \"@context\": [\"https://w3id.org/zcap/v1\", \"https://w3id.org/security/data-integrity/v2\", \" \"],\n",
    "    \"patch\": json_patch_update_repr,\n",
    "    \"proof\": {\n",
    "        \"type\": \"DataIntegrityProof\",\n",
    "        \"cryptosuite\": \"secp-schnorr-2024\",\n",
    "        \"verificationMethod\": \"did:btc:6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis#initialKey\",\n",
    "        \"invocationTarget\": \"did:btc:6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis\",\n",
    "        \"capability\": \"urn:zcap:root:did%3Abtc%3A6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis\",\n",
    "        \"capabilityAction\": \"Write\",\n",
    "        \"proofPurpose\": \"assertionMethod\",\n",
    "        \"proofValue\": signature\n",
    "  }\n",
    "}\n",
    "\n",
    "zcaps_invocation_update_payload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c14a3-e6d0-4705-94e2-b79c8c439efa",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "The first thing I would emphasise is that the ZCap spec is very much a work in progress. If we went down this route it is something we would likely have to take on and champion. Doing this would also mean we could shape it though. For example, it is not at all clear to my why the `proof` needs the `capabilityAction` property, in fact the spec is a little contradictory here. I also would like to know why we need the `invocationTarget`, when it is specified by the `capability`. It feels like we are duplicating things. So it may be possible that all that is required to use ZCaps, would be an additional property in the `proof` (`capability`) AND an additional `@context` value (https://w3id.org/zcap/v1).\n",
    "\n",
    "### What do we get for this anyway?\n",
    "\n",
    "The update payload is self contained and self describing. Our spec still defines the custom way to dereference a capability ID to retrieve the root capability. But the payload clearly describes what it is, a capability that is invoked at the target (a DID). The cost for this seems minimal and is greatly reduces the complexity of the spec we have to write. Because the only custom part of this is how to deterministically dereference a capability ID. Additionally AND optionally we get a coherent mechanism to describe delegation and scoping of actions. This of course would require additional fields and increase the size of the update payload. There is also some non-trivial complexity around how we support this with beacons.\n",
    "\n",
    "However, I think the question of delegation and action scoping should be a separate discussion. It at least does not feel like a priority, but a nice to have that we might explore in the future. I personally, after working through this notebook, have become more convinced that ZCaps make sense and do not unreasonably increase the number of bytes required for an update payload.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340c8045-7a5c-4a7f-97d3-0c034ecb8f8d",
   "metadata": {},
   "source": [
    "# 5. Size Analysis for Typical Updates \n",
    "\n",
    "I am going to look at the size of different update payloads for a set of typical updates expected to be performed by a DID controller on a DID document. The updates are as follows:\n",
    "\n",
    "1. Adding a service \n",
    "2. Replacing a beacon service\n",
    "3. Adding a verificationMethod and authentication verificationRelationship & removing a service\n",
    "4. Rotating (replacing) all (4) verificationMethods in the DID document. Keeping the same IDs - no need to change verificationRelationships\n",
    "\n",
    "For each of these four updates I will look at the sizes of the following objects\n",
    "\n",
    "1. The JSON patch update\n",
    "2. A signature (invariant - always the same size)\n",
    "3. JSON secured with Data Integrity\n",
    "4. JSONLD secured with Data Integrity\n",
    "5. ZCAP_LD\n",
    "\n",
    "Where the payload is JSONLD I will include numbers for CBORLD compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d74cac8-a7e8-4d23-bc9a-b61616110486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Adding a LinkedDomain service\n",
    "add_service = [{'op': 'add',\n",
    "  'path': '/service/4',\n",
    "  'value': {'id': '#linked-domain',\n",
    "   'type': 'LinkedDomains',\n",
    "   'serviceEndpoint': 'https://contact-me.com'}}]\n",
    "\n",
    "\n",
    "# 2. Replacing a beacon service\n",
    "replace_beacon_service = [{'op': 'replace',\n",
    "  'path': '/service/4',\n",
    "  'value': {'id': '#smt_aggregated',\n",
    " 'type': 'SMTAggregatedBTCBeacon',\n",
    " 'serviceEndpoint': 'bitcoin:tb1pfdnyc8vxeca2zpsg365sn308dmrpka4e0n9c5axmp2nptdf7j6ts7eqhr8'}\n",
    "  }]\n",
    "\n",
    "\n",
    "# 3. Adding a verificationMethod and authentication verificationRelationship & removing a service\n",
    "add_vm_auth_remove_service = [\n",
    "    {'op': 'remove', 'path': '/service/4'},\n",
    "    {'op': 'add', 'path': '/verificationMethod/1', 'value': {\n",
    "        \"id\": \"#auth-keys-1\",\n",
    "        \"type\": \"Ed25519VerificationKey2020\",\n",
    "        \"controller\": \"did:btc:5kq8whVLtvEgLhhY2uKff2GSv3sBKDKcQKiwSTLNuqeh\",\n",
    "        \"publicKeyMultibase\": \"zH3C2AVvLMv6gmMNam3uVAjZpfkcJCwDwnZn6z3wXmqPV\"\n",
    "        }\n",
    "    },\n",
    "     {'op': 'add', 'path': '/authentication/1', 'value': '#auth-keys-1'}\n",
    "]\n",
    "\n",
    "\n",
    "# 4. Rotating (replacing) all (4) verificationMethods in the DID document. Keeping the same IDs - no need to change verificationRelationships\n",
    "rotate_vms = [\n",
    "    {'op': 'replace', 'path': '/verificationMethod/0', 'value': {\n",
    "      \"id\": \"#keys-1\",\n",
    "      \"type\": \"EcdsaSecp256k1VerificationKey2019\",\n",
    "      \"controller\": \"did:btc:5kq8whVLtvEgLhhY2uKff2GSv3sBKDKcQKiwSTLNuqeh\",\n",
    "      \"publicKeyHex\" : \"034ee0f670fc96bb75e8b89c068a1665007a41c98513d6a911b6137e2d16f1d300\"\n",
    "    }\n",
    "    },\n",
    "    {'op': 'replace', 'path': '/verificationMethod/2', 'value': {\n",
    "      \"id\": \"#keys-2\",\n",
    "      \"type\": \"EcdsaSecp256k1VerificationKey2019\",\n",
    "      \"controller\": \"did:btc:5kq8whVLtvEgLhhY2uKff2GSv3sBKDKcQKiwSTLNuqeh\",\n",
    "      \"publicKeyHex\" : \"034ee0f670fc96bb75e8b89c068a1665007a41c98513d6a911b6137e2d16f1d300\"\n",
    "    }\n",
    "    },\n",
    "    {'op': 'replace', 'path': '/verificationMethod/3', 'value': {\n",
    "      \"id\": \"#keys-3\",\n",
    "      \"type\": \"EcdsaSecp256k1VerificationKey2019\",\n",
    "      \"controller\": \"did:btc:5kq8whVLtvEgLhhY2uKff2GSv3sBKDKcQKiwSTLNuqeh\",\n",
    "      \"publicKeyHex\" : \"034ee0f670fc96bb75e8b89c068a1665007a41c98513d6a911b6137e2d16f1d300\"\n",
    "    }\n",
    "        },\n",
    "    {'op': 'replace', 'path': '/verificationMethod/4', 'value': {\n",
    "      \"id\": \"#keys-4\",\n",
    "        \"type\": \"Ed25519VerificationKey2020\",\n",
    "        \"controller\": \"did:btc:5kq8whVLtvEgLhhY2uKff2GSv3sBKDKcQKiwSTLNuqeh\",\n",
    "        \"publicKeyMultibase\": \"zH3C2AVvLMv6gmMNam3uVAjZpfkcJCwDwnZn6z3wXmqPV\"\n",
    "    }\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "size1_patch = sys.getsizeof(json.dumps(add_service))\n",
    "size2_patch = sys.getsizeof(json.dumps(replace_beacon_service))\n",
    "size3_patch = sys.getsizeof(json.dumps(add_vm_auth_remove_service))\n",
    "size4_patch = sys.getsizeof(json.dumps(rotate_vms))\n",
    "\n",
    "\n",
    "# complex_json_patch_size = sys.getsizeof(json.dumps(more_complex_json_patch_update))\n",
    "\n",
    "# print(\"Complex JSON Patch\")\n",
    "# print(more_complex_json_patch_update)\n",
    "# print(\"Size : \", complex_json_patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ade3452-2aec-4a31-8ce2-417c1577b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "di_proof = {\n",
    "        \"type\": \"DataIntegrityProof\",\n",
    "        \"cryptosuite\": \"secp-schnorr-2024\",\n",
    "        \"verificationMethod\": \"did:btc:6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis#initialKey\",\n",
    "        \"proofPurpose\": \"assertionMethod\",\n",
    "        \"proofValue\": signature\n",
    "}\n",
    "\n",
    "zcap_proof = copy.deepcopy(di_proof)\n",
    "zcap_proof[\"invocationTarget\"] = \"did:btc:6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis\"\n",
    "zcap_proof[\"capability\"] = \"urn:zcap:root:did%3Abtc%3A6itLKk6UfdvCu4LFdWmJgGZt2JSCZbn4YrNhzhSRTxis\"\n",
    "zcap_proof[\"capabilityAction\"] =\"Write\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798960d8-43b7-4e06-9331-c654321c027e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2a20a3d-8407-4b4e-b16a-54da64c976e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_di_1 = {\n",
    "    'patch': add_service,\n",
    "    'proof': di_proof\n",
    "}\n",
    "\n",
    "jsonld_di_1 = {\n",
    "    \"@context\": [\"https://w3id.org/security/data-integrity/v2\", \"https://w3id.org/json-ld-patch/v1\"],\n",
    "    'patch': add_service,\n",
    "    'proof': di_proof\n",
    "}\n",
    "\n",
    "zcap_1 = {\n",
    "    \"@context\": [\"https://w3id.org/zcap/v1\", \"https://w3id.org/security/data-integrity/v2\", \"https://w3id.org/json-ld-patch/v1\"],\n",
    "    'patch': add_service,\n",
    "    'proof': zcap_proof\n",
    "}\n",
    "\n",
    "size_json_di_1 = sys.getsizeof(json.dumps(json_di_1))\n",
    "size_jsonld_di_1 = sys.getsizeof(json.dumps(jsonld_di_1))\n",
    "size_zcap_1 = sys.getsizeof(json.dumps(zcap_1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a44175-b4c6-4645-a3f0-bd105ae0152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_di_2 = {\n",
    "    'patch': replace_beacon_service,\n",
    "    'proof': di_proof\n",
    "}\n",
    "\n",
    "jsonld_di_2 = {\n",
    "    \"@context\": [\"https://w3id.org/security/data-integrity/v2\", \"https://w3id.org/json-ld-patch/v1\"],\n",
    "    'patch': replace_beacon_service,\n",
    "    'proof': di_proof\n",
    "}\n",
    "\n",
    "zcap_2 = {\n",
    "    \"@context\": [\"https://w3id.org/zcap/v1\", \"https://w3id.org/security/data-integrity/v2\", \"https://w3id.org/json-ld-patch/v1\"],\n",
    "    'patch': replace_beacon_service,\n",
    "    'proof': zcap_proof\n",
    "}\n",
    "\n",
    "size_json_di_2 = sys.getsizeof(json.dumps(json_di_2))\n",
    "size_jsonld_di_2 = sys.getsizeof(json.dumps(jsonld_di_2))\n",
    "size_zcap_2 = sys.getsizeof(json.dumps(zcap_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30ed46c4-ed2d-489c-ad65-9ddde1f8500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_di_3 = {\n",
    "    'patch': add_vm_auth_remove_service,\n",
    "    'proof': di_proof\n",
    "}\n",
    "\n",
    "jsonld_di_3 = {\n",
    "    \"@context\": [\"https://w3id.org/security/data-integrity/v2\", \"https://w3id.org/json-ld-patch/v1\"],\n",
    "    'patch': add_vm_auth_remove_service,\n",
    "    'proof': di_proof\n",
    "}\n",
    "\n",
    "zcap_3 = {\n",
    "    \"@context\": [\"https://w3id.org/zcap/v1\", \"https://w3id.org/security/data-integrity/v2\", \"https://w3id.org/json-ld-patch/v1\"],\n",
    "    'patch': add_vm_auth_remove_service,\n",
    "    'proof': zcap_proof\n",
    "}\n",
    "\n",
    "size_json_di_3 = sys.getsizeof(json.dumps(json_di_3))\n",
    "size_jsonld_di_3 = sys.getsizeof(json.dumps(jsonld_di_3))\n",
    "size_zcap_3 = sys.getsizeof(json.dumps(zcap_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a6bf1a1-f1f6-4876-9d20-1a4130883b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_di_4 = {\n",
    "    'patch': rotate_vms,\n",
    "    'proof': di_proof\n",
    "}\n",
    "\n",
    "jsonld_di_4 = {\n",
    "    \"@context\": [\"https://w3id.org/security/data-integrity/v2\", \"https://w3id.org/json-ld-patch/v1\"],\n",
    "    'patch': rotate_vms,\n",
    "    'proof': di_proof\n",
    "}\n",
    "\n",
    "zcap_4 = {\n",
    "    \"@context\": [\"https://w3id.org/zcap/v1\", \"https://w3id.org/security/data-integrity/v2\", \"https://w3id.org/json-ld-patch/v1\"],\n",
    "    'patch': rotate_vms,\n",
    "    'proof': zcap_proof\n",
    "}\n",
    "\n",
    "size_json_di_4 = sys.getsizeof(json.dumps(json_di_4))\n",
    "size_jsonld_di_4 = sys.getsizeof(json.dumps(jsonld_di_4))\n",
    "size_zcap_4 = sys.getsizeof(json.dumps(zcap_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03829991-0080-4a16-8844-7d9757fa4202",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Below shows the table of results, sizes of objects are in bytes. It is worth highlighting again that only one of these objects, the ZCap is an authorization object. To make any of the other objects authorization objects we would need to add additional properties and hence increase the size of the payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f25b136c-8b06-46ff-944b-d28b89ce504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e96fa8b-8e74-41eb-9bd4-8ea636682ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update Type         JSON Patch    Sig    JSON DI    JSONLD DI    ZCAPLD\n",
      "----------------  ------------  -----  ---------  -----------  --------\n",
      "Add Service                183    138        510          608       829\n",
      "Replace Beacon             245    138        572          670       891\n",
      "Add VM, Auth Rel           410    138        737          835      1056\n",
      "Rotate VMs                1143    138       1470         1568      1789\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[\"Update Type\",\"JSON Patch\", \"Sig\", \"JSON DI\", \"JSONLD DI\", \"ZCAPLD\"],\n",
    "                 [\"Add Service\",size1_patch, sig_size, size_json_di_1, size_jsonld_di_1, size_zcap_1],\n",
    "                 [\"Replace Beacon\",size2_patch, sig_size, size_json_di_2, size_jsonld_di_2, size_zcap_2],\n",
    "                 [\"Add VM, Auth Rel\",size3_patch, sig_size, size_json_di_3, size_jsonld_di_3, size_zcap_3],\n",
    "                 [\"Rotate VMs\",size4_patch, sig_size, size_json_di_4, size_jsonld_di_4, size_zcap_4]\n",
    "                ], headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c84184-003b-4387-9c36-cc19166307b3",
   "metadata": {},
   "source": [
    "# 6. What is too big in this context?\n",
    "\n",
    "The size of these updates will depend on the size of the update that we are doing to our DID document. However, given this is ~829 bytes I would not expect this size to exceed 2000 bytes. The only other reason the size of the update payload MIGHT increase, is if we decide to support delegation. However, I think ZCAPs without delegation are still valuable because of the self describing nature of the payload. \n",
    "\n",
    "These update payloads need to:\n",
    "\n",
    "1. Be stored by DID controllers for the duration of the lifetime of their DIDs\n",
    "2. Be sent over the wire to resolvers, either retrieved from a CAS like IPFS or directly communicated by DID controllers\n",
    "\n",
    "For 1., too big is the total size of all the update payloads a DID controller has to store is unreasonable. For example, lets imagine this size is 10Gb (Which is fairly small and definitely accessible to most people). And lets imagine the average update is 2000 Bytes. **10Gb / 2000 bytes = 625 000 updates**. Which is the number of updates it is possible to store before this gets unreasonable. \n",
    "\n",
    "For 2., 2000 bytes is roughly equivalent to a page of text. So that seems fine to send over the wire. However, we should remember that a resolver must retrieve all updates associated with the DID they are resolving. So how many update might this be? Imagine I am especially security conscious and I update my DID every week for 10 years. 52 * 10 = 520 updates. 520 * 2000 =~ 1Mb, or less than the average webpage (~2Mb). I would assert that is also fine to send over the wire without issues.\n",
    "\n",
    "**Note: These rough back of the envolope calculations have been done BEFORE considering compression mechanisms such as CBORLD.**\n",
    "\n",
    "**Further Note: These calculations are extremely conservative. I find it unlikely that 10Gb is the size of a store deemed unresonably large for most usecases. An average of 2000 bytes per update also seems exagerated, given it is likely people are making minor changes to their DID documents like adding or removing a service or verificationMethod. Perhaps ~1000 bytes average is more reasonable. I am also unsure of the use case that would require a single DID to be updated every week. Those who security/privacy conscious are much more likely to change DIDs regularly than update the DID document of a single DID.**\n",
    "\n",
    "Byte equivalents taken from here - https://www.techtarget.com/searchstorage/definition/How-many-bytes-for \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c824e1-e75c-4a20-93dd-5cb1bb1e7331",
   "metadata": {},
   "source": [
    "# 7. What about compression?\n",
    "\n",
    "If we care about the size, we can look at compression. If we are using JSONLD, then we can make use of CBORLD which compresses JSONLD using the keys from the @context file. \n",
    "\n",
    "Unfortunately CBORLD appears to only be implemented by Digital Bazaar and only implemented in [JavaScript](https://github.com/digitalbazaar/cborld). However, I would expect that to change given the Verifiable Credential Barcode work and the interest in this work by governments\n",
    "\n",
    "The table below shows the compression sizes for CBORLD and bzip applied to the ZCAP object from above.\n",
    "\n",
    "I used the Db JS library to compress the above ZCAP payload using JSONLD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ed361aa-48da-4e29-ab90-53edb1f95553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBORLD Size values\n",
    "# Calculated using https://github.com/digitalbazaar/cborld\n",
    "cborld_1 = 454\n",
    "cborld_2 = 517\n",
    "cborld_3 = 625\n",
    "cborld_4 = 1225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcfd938d-703b-4360-9ae1-12bef4167132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "\n",
    "bzip_zcap_1 = bz2.compress(json.dumps(zcap_1).encode('utf-8'))\n",
    "bzip_zcap_2 = bz2.compress(json.dumps(zcap_2).encode('utf-8'))\n",
    "bzip_zcap_3 = bz2.compress(json.dumps(zcap_3).encode('utf-8'))\n",
    "bzip_zcap_4 = bz2.compress(json.dumps(zcap_4).encode('utf-8'))\n",
    "\n",
    "bzip_size_1 = len(bzip_zcap_1)\n",
    "bzip_size_2 = len(bzip_zcap_2)\n",
    "bzip_size_3 = len(bzip_zcap_3)\n",
    "bzip_size_4 = len(bzip_zcap_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0d61182-00d5-4613-ace1-261f523a8645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update Payload            ZCAPLD Size    CBORLD Size    BZip Size\n",
      "----------------------  -------------  -------------  -----------\n",
      "Add Service                       829            454          571\n",
      "Replace Beacon Service            891            517          622\n",
      "Add VM & Auth Rel                1056            625          685\n",
      "Rotate VMs                       1789           1225          865\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[\"Update Payload\", \"ZCAPLD Size\", \"CBORLD Size\", \"BZip Size\"], \n",
    "                [\"Add Service\", size_zcap_1, cborld_1, bzip_size_1],\n",
    "                [\"Replace Beacon Service\", size_zcap_2, cborld_2, bzip_size_2],\n",
    "                [\"Add VM & Auth Rel\", size_zcap_3, cborld_3, bzip_size_3],\n",
    "                [\"Rotate VMs\", size_zcap_4, cborld_4, bzip_size_4]\n",
    "               ], headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ec083-899d-42b4-a94c-9d7021a48bec",
   "metadata": {},
   "source": [
    "# 8. Conclusion\n",
    "\n",
    "## What do we get if we use ZCaps-LD?\n",
    "\n",
    "If we decide to go with ZCaps-LD, we get a JSON-LD data model and associated context for a self-describing authorization object with an existing specification draft. The ZCaps-LD specification is currently a community draft at the W3C CCG and needs work, but it exists and provides a foundation to build on. Furthermore, this provides, at a minimum conceptual, alignment with existing efforts within this space such as the VC-API. The size of a ZCaps-LD object is necessarily larger than a plain JSONLD object sercured with Data Integrity, ~221 bytes by the analysis in this notebook, however a plain JSONLD object is not an authorization object and can only be understood within the context of a specific custom protocol. To turn the JSONLD object into a self-describing authorization object we would have to add additional fields making the payload larger. While we could define these fields for ourselves and the write a specification for them, ZCaps-LD has make great progress in this area. Finally, ZCaps-LD because it is linked data can make use of CBOR-LD compression if required.\n",
    "\n",
    "## What do we get if we don't use ZCaps-LD?\n",
    "\n",
    "If we decide not to go with ZCaps-LD we would require to either choose or define another authorization object. There are other capabilities specification that define authorization objects, for example [UCAN](ucan.xyz), however these are secured using different mechanisms (e.g. JWT). To our knowledge, ZCaps-LD is the only capabilities specification within the JSON-LD landscape and since we have already agreed that we will be securing JSON-LD VC's and we prefer Data Integrity over JWTs then it makes sense to use Data Integrity to secure the update payload. If we want to define our own authorization object, we have to define the data model for this object. This would mean repeating much of the work that ZCaps-LD has already started.\n",
    "\n",
    "## Why do we need the update payload to be an authorization object?\n",
    "\n",
    "Without an authorization object it is impossible to know what signed data object means and how it should be interpretted. Authorization objects or capabilities define the target of the capability, the DID document in our case, furthermore they provide a clear mechanism for interpretting and verifying who is authorized to invoke this capability - who can update a DID document in our case.\n",
    "\n",
    "## What about the size of these things?\n",
    "\n",
    "Per the discussion in Section 6, we do not believe the size of the ZCap-LD authorization objects to be a concern for most usecases. Back of the envelope calculations suggest that 10 Gb of storage would enable the storage of 625000 updates of size 2000 bytes. Note, all of the example updates tested in Section 5 were smaller than 2000 bytes. When providing a chain of updates for a single DID document over the wire, 1Mb would be enough to send 520 2000 byte updates. Which would mean a DID that has updated every week for 10 years. All of these numbers seem reasonable. If there are concerns about the size of these objects, Section 7 suggests compression of ~40% is possible using either CBOR-LD or bzip. While the spec could mandate a particular compression format, another option available to any DID controller is to compress the data objects they are required to store in a manner they choose as suitable to their use case. Note, in this case they would have to uncompress the data and send JSON-LD over the wire.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834da193-bc44-492e-870b-dbe174ff4ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
